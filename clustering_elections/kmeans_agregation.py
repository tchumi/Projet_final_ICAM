"""
Ce script effectue un clustering des rÃ©sultats Ã©lectoraux en utilisant l'algorithme K-Means.
FonctionnalitÃ©s principales :
- Chargement des donnÃ©es Ã©lectorales Ã  partir d'un fichier CSV.
- SÃ©lection et standardisation des variables Ã©lectorales pour le 1er et le 2nd tour.
- DÃ©termination du nombre optimal de clusters Ã  l'aide de la mÃ©thode du coude.
- Application de l'algorithme K-Means pour chaque annÃ©e d'Ã©lection.
- Stockage des rÃ©sultats des clusters et fusion avec les donnÃ©es originales.
- Sauvegarde des rÃ©sultats finaux dans un fichier CSV.
BibliothÃ¨ques utilisÃ©es :
- pandas : pour la manipulation des donnÃ©es.
- os : pour la gestion des chemins de fichiers.
- matplotlib.pyplot et seaborn : pour la visualisation des donnÃ©es.
- sklearn.cluster et sklearn.preprocessing : pour le clustering et la standardisation des donnÃ©es.
- yellowbrick.cluster : pour la visualisation du nombre optimal de clusters.
Variables :
- DATA_DIR : chemin du rÃ©pertoire contenant les donnÃ©es.
- INPUT_FILE : chemin du fichier CSV d'entrÃ©e contenant les donnÃ©es Ã©lectorales.
- OUTPUT_FILE : chemin du fichier CSV de sortie pour sauvegarder les rÃ©sultats des clusters.
- variables_1er_tour : liste des variables Ã©lectorales pour le 1er tour.
- variables_2nd_tour : liste des variables Ã©lectorales pour le 2nd tour.
- scaler : instance de StandardScaler pour la standardisation des donnÃ©es.
- clusters_results : liste pour stocker les rÃ©sultats des clusters pour chaque annÃ©e.
Ã‰tapes principales :
1. Chargement des donnÃ©es Ã©lectorales.
2. Boucle sur chaque annÃ©e d'Ã©lection pour effectuer le clustering.
3. Standardisation des variables Ã©lectorales.
4. DÃ©termination du nombre optimal de clusters pour le 1er et le 2nd tour.
5. Application de l'algorithme K-Means et stockage des rÃ©sultats.
6. Fusion des rÃ©sultats des clusters avec les donnÃ©es originales.
7. Sauvegarde des rÃ©sultats finaux dans un fichier CSV.

"""


import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from yellowbrick.cluster import KElbowVisualizer

# ğŸ“ Chemins des fichiers
DATA_DIR = "C:/Users/Admin.local/Documents/Projet_final_data/Piketty_data"
INPUT_FILE = os.path.join(DATA_DIR, "elections_fusionnees_cleaned_with_names.csv")
OUTPUT_FILE = os.path.join(DATA_DIR, "elections_fusionnees_cleaned_with_names_clusters.csv")

# ğŸ“Œ Chargement des donnÃ©es
df = pd.read_csv(INPUT_FILE, sep=",", dtype={"codecommune": str})

# ğŸ“Œ SÃ©lection des variables Ã©lectorales pour clustering
variables_1er_tour = ["pvoteG", "pvoteCG", "pvoteC", "pvoteCD", "pvoteD", "pvoteTG", "pvoteTD"]
variables_2nd_tour = ["pvoteT2_ED", "pvoteT2_D", "pvoteT2_CD", "pvoteT2_C", "pvoteT2_G"]

# ğŸ“Œ Standardisation des donnÃ©es
scaler = StandardScaler()

# ğŸ“Œ Dictionnaire pour stocker les rÃ©sultats des clusters
clusters_results = []

# ğŸ“Œ Boucle sur chaque Ã©lection
for year in df["annÃ©e"].unique():
    print(f"ğŸ”„ Clustering pour l'Ã©lection de {year}...")
    
    # ğŸ“Œ SÃ©lection des donnÃ©es de lâ€™annÃ©e
    df_year = df[df["annÃ©e"] == year].copy()
    
    # ğŸ“Œ Standardisation des variables Ã©lectorales
    X_1er_tour = scaler.fit_transform(df_year[variables_1er_tour])
    X_2nd_tour = scaler.fit_transform(df_year[variables_2nd_tour])

    # ğŸ“Œ Trouver le nombre optimal de clusters avec la mÃ©thode du coude
    elbow_1er = KElbowVisualizer(KMeans(n_init=10), k=(2, 10))
    elbow_1er.fit(X_1er_tour)
    k_1er = elbow_1er.elbow_value_
    
    elbow_2nd = KElbowVisualizer(KMeans(n_init=10), k=(2, 10))
    elbow_2nd.fit(X_2nd_tour)
    k_2nd = elbow_2nd.elbow_value_

    # ğŸ“Œ Appliquer K-Means avec le nombre optimal de clusters
    kmeans_1er = KMeans(n_clusters=k_1er, n_init=10, random_state=42).fit(X_1er_tour)
    kmeans_2nd = KMeans(n_clusters=k_2nd, n_init=10, random_state=42).fit(X_2nd_tour)

    # ğŸ“Œ Stocker les clusters trouvÃ©s
    df_year["cluster_1er_tour"] = kmeans_1er.labels_
    df_year["cluster_2nd_tour"] = kmeans_2nd.labels_

    clusters_results.append(df_year[["codecommune", "annÃ©e", "cluster_1er_tour", "cluster_2nd_tour"]])

# ğŸ“Œ Fusion des rÃ©sultats des clusters
df_clusters = pd.concat(clusters_results, ignore_index=True)

# ğŸ“Œ Fusion avec les donnÃ©es originales
df_final = df.merge(df_clusters, on=["codecommune", "annÃ©e"], how="left")

# ğŸ“Œ Sauvegarde du fichier final
df_final.to_csv(OUTPUT_FILE, index=False)

print(f"âœ… Clustering terminÃ© ! Fichier final sauvegardÃ© sous {OUTPUT_FILE}")
