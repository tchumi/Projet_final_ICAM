import pandas as pd
import os
from scipy.spatial.distance import euclidean
from itertools import product

# ğŸ“ Chemin des fichiers
DATA_DIR = "C:/Users/Admin.local/Documents/Projet_final_data/Piketty_data"
CLUSTER_FILE = os.path.join(DATA_DIR, "clusters_elections.csv")
ELECTIONS_FILE = os.path.join(DATA_DIR, "elections_fusionnees_cleaned_with_names.csv")
REPORT_FILE = os.path.join(DATA_DIR, "rapport_evolution_politique_clusters_pondere_corrige_final.txt")

# ğŸ“Œ Chargement des fichiers
df_clusters = pd.read_csv(CLUSTER_FILE, sep=",", dtype={"codecommune": str})
df_votes = pd.read_csv(ELECTIONS_FILE, sep=",", dtype={"codecommune": str})

# ğŸ“Œ SÃ©lection des colonnes Ã©lectorales Ã  analyser
variables_votes = ["pvoteG", "pvoteCG", "pvoteC", "pvoteCD", "pvoteD"]
ponderation = "exprimes"  # Nombre de votes exprimÃ©s pour pondÃ©rer les moyennes

# ğŸ“Œ VÃ©rification des colonnes disponibles
votes_disponibles = [col for col in variables_votes if col in df_votes.columns]

# ğŸ“Œ Fusionner les donnÃ©es des clusters avec les donnÃ©es de vote
df_merged = df_clusters.merge(df_votes[["codecommune", "annÃ©e", ponderation] + votes_disponibles], on=["codecommune", "annÃ©e"], how="left")

# ğŸ“Œ Fonction pour analyser lâ€™Ã©volution des clusters en utilisant des moyennes pondÃ©rÃ©es
def suivre_clusters_par_profil_pondere(df):
    rapport = []
    
    for annee1, annee2 in zip(sorted(df["annÃ©e"].unique())[:-1], sorted(df["annÃ©e"].unique())[1:]):
        df_prev = df[df["annÃ©e"] == annee1]
        df_next = df[df["annÃ©e"] == annee2]

        # Calcul des moyennes pondÃ©rÃ©es des votes par cluster
        def weighted_mean(df_grouped, var):
            return (df_grouped[var] * df_grouped[ponderation]).sum() / df_grouped[ponderation].sum()

        # Exclure la colonne de regroupement et appliquer la fonction sur les autres colonnes uniquement
        stats_prev = df_prev.groupby("cluster_1er_tour")[votes_disponibles + [ponderation]].apply(
            lambda x: pd.Series({var: weighted_mean(x, var) for var in votes_disponibles})
        ).reset_index()

        stats_next = df_next.groupby("cluster_1er_tour")[votes_disponibles + [ponderation]].apply(
            lambda x: pd.Series({var: weighted_mean(x, var) for var in votes_disponibles})
        ).reset_index()

        # Associer les clusters d'une Ã©lection Ã  l'autre en fonction de leur proximitÃ© Ã©lectorale
        cluster_mapping = {}
        distances = []
        
        for cluster1, cluster2 in product(stats_prev["cluster_1er_tour"], stats_next["cluster_1er_tour"]):
            dist = euclidean(stats_prev.loc[stats_prev["cluster_1er_tour"] == cluster1, votes_disponibles].values[0], 
                             stats_next.loc[stats_next["cluster_1er_tour"] == cluster2, votes_disponibles].values[0])
            distances.append((cluster1, cluster2, dist))
        
        # Trier par distance pour faire correspondre les clusters les plus proches
        distances.sort(key=lambda x: x[2])
        
        matched_clusters = set()
        for cluster1, cluster2, dist in distances:
            if cluster1 not in cluster_mapping and cluster2 not in matched_clusters:
                cluster_mapping[cluster1] = cluster2
                matched_clusters.add(cluster2)

        rapport.append(f"\nğŸ“Œ Correspondance des clusters entre {annee1} et {annee2} (moyennes pondÃ©rÃ©es) :")
        for cluster1, cluster2 in cluster_mapping.items():
            changements = stats_next.loc[stats_next["cluster_1er_tour"] == cluster2, votes_disponibles].values[0] - stats_prev.loc[stats_prev["cluster_1er_tour"] == cluster1, votes_disponibles].values[0]
            rapport.append(f"\nâ¡ï¸ Cluster {cluster1} ({annee1}) â Cluster {cluster2} ({annee2}) :")
            rapport.append(pd.Series(changements, index=votes_disponibles).to_string())

    return "\n".join(rapport)

# ğŸ“Œ GÃ©nÃ©ration du rapport
rapport_final = "ğŸ“Š Suivi de l'Ã©volution des clusters avec moyennes pondÃ©rÃ©es (Correction DÃ©finitive Pandas)\n"
rapport_final += "======================================\n\n"
rapport_final += suivre_clusters_par_profil_pondere(df_merged)

# ğŸ“Œ Sauvegarde du rapport
with open(REPORT_FILE, "w", encoding="utf-8") as file:
    file.write(rapport_final)

print(f"âœ… Rapport gÃ©nÃ©rÃ© avec moyennes pondÃ©rÃ©es et correction complÃ¨te des warnings : {REPORT_FILE}")
