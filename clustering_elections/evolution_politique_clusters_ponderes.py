"""
Ce script analyse l'√©volution des clusters politiques en utilisant des moyennes pond√©r√©es des r√©sultats √©lectoraux.
Modules import√©s:
- pandas: pour la manipulation des donn√©es
- os: pour la gestion des chemins de fichiers
- scipy.spatial.distance.euclidean: pour calculer la distance euclidienne entre les clusters
- itertools.product: pour g√©n√©rer des paires de clusters √† comparer
Variables globales:
- DATA_DIR: chemin du r√©pertoire contenant les fichiers de donn√©es
- CLUSTER_FILE: chemin du fichier contenant les donn√©es des clusters
- ELECTIONS_FILE: chemin du fichier contenant les donn√©es √©lectorales
- REPORT_FILE: chemin du fichier o√π le rapport sera sauvegard√©
- variables_votes: liste des colonnes √©lectorales √† analyser
- ponderation: colonne utilis√©e pour pond√©rer les moyennes
Fonctions:
- suivre_clusters_par_profil_pondere(df): analyse l'√©volution des clusters en utilisant des moyennes pond√©r√©es des r√©sultats √©lectoraux et g√©n√®re un rapport.
√âtapes principales:
1. Chargement des fichiers de donn√©es des clusters et des votes.
2. S√©lection des colonnes √©lectorales disponibles dans les donn√©es.
3. Fusion des donn√©es des clusters avec les donn√©es de vote.
4. Analyse de l'√©volution des clusters par ann√©e en utilisant des moyennes pond√©r√©es.
5. G√©n√©ration et sauvegarde du rapport final.
Le rapport final est sauvegard√© dans un fichier texte sp√©cifi√© par REPORT_FILE.

"""
import pandas as pd
import os
from scipy.spatial.distance import euclidean
from itertools import product

# üìç Chemin des fichiers
DATA_DIR = "C:/Users/Admin.local/Documents/Projet_final_data/Piketty_data"
CLUSTER_FILE = os.path.join(DATA_DIR, "clusters_elections.csv")
ELECTIONS_FILE = os.path.join(DATA_DIR, "elections_fusionnees_cleaned_with_names.csv")
REPORT_FILE = os.path.join(DATA_DIR, "rapport_evolution_politique_clusters_pondere_corrige_final.txt")

# üìå Chargement des fichiers
df_clusters = pd.read_csv(CLUSTER_FILE, sep=",", dtype={"codecommune": str})
df_votes = pd.read_csv(ELECTIONS_FILE, sep=",", dtype={"codecommune": str})

# üìå S√©lection des colonnes √©lectorales √† analyser
variables_votes = ["pvoteG", "pvoteCG", "pvoteC", "pvoteCD", "pvoteD"]
ponderation = "exprimes"  # Nombre de votes exprim√©s pour pond√©rer les moyennes

# üìå V√©rification des colonnes disponibles
votes_disponibles = [col for col in variables_votes if col in df_votes.columns]

# üìå Fusionner les donn√©es des clusters avec les donn√©es de vote
df_merged = df_clusters.merge(df_votes[["codecommune", "ann√©e", ponderation] + votes_disponibles], on=["codecommune", "ann√©e"], how="left")

# üìå Fonction pour analyser l‚Äô√©volution des clusters en utilisant des moyennes pond√©r√©es
def suivre_clusters_par_profil_pondere(df):
    rapport = []
    
    for annee1, annee2 in zip(sorted(df["ann√©e"].unique())[:-1], sorted(df["ann√©e"].unique())[1:]):
        df_prev = df[df["ann√©e"] == annee1]
        df_next = df[df["ann√©e"] == annee2]

        # Calcul des moyennes pond√©r√©es des votes par cluster
        def weighted_mean(df_grouped, var):
            return (df_grouped[var] * df_grouped[ponderation]).sum() / df_grouped[ponderation].sum()

        # Exclure la colonne de regroupement et appliquer la fonction sur les autres colonnes uniquement
        stats_prev = df_prev.groupby("cluster_1er_tour")[votes_disponibles + [ponderation]].apply(
            lambda x: pd.Series({var: weighted_mean(x, var) for var in votes_disponibles})
        ).reset_index()

        stats_next = df_next.groupby("cluster_1er_tour")[votes_disponibles + [ponderation]].apply(
            lambda x: pd.Series({var: weighted_mean(x, var) for var in votes_disponibles})
        ).reset_index()

        # Associer les clusters d'une √©lection √† l'autre en fonction de leur proximit√© √©lectorale
        cluster_mapping = {}
        distances = []
        
        for cluster1, cluster2 in product(stats_prev["cluster_1er_tour"], stats_next["cluster_1er_tour"]):
            dist = euclidean(stats_prev.loc[stats_prev["cluster_1er_tour"] == cluster1, votes_disponibles].values[0], 
                             stats_next.loc[stats_next["cluster_1er_tour"] == cluster2, votes_disponibles].values[0])
            distances.append((cluster1, cluster2, dist))
        
        # Trier par distance pour faire correspondre les clusters les plus proches
        distances.sort(key=lambda x: x[2])
        
        matched_clusters = set()
        for cluster1, cluster2, dist in distances:
            if cluster1 not in cluster_mapping and cluster2 not in matched_clusters:
                cluster_mapping[cluster1] = cluster2
                matched_clusters.add(cluster2)

        rapport.append(f"\nüìå Correspondance des clusters entre {annee1} et {annee2} (moyennes pond√©r√©es) :")
        for cluster1, cluster2 in cluster_mapping.items():
            changements = stats_next.loc[stats_next["cluster_1er_tour"] == cluster2, votes_disponibles].values[0] - stats_prev.loc[stats_prev["cluster_1er_tour"] == cluster1, votes_disponibles].values[0]
            rapport.append(f"\n‚û°Ô∏è Cluster {cluster1} ({annee1}) ‚ûù Cluster {cluster2} ({annee2}) :")
            rapport.append(pd.Series(changements, index=votes_disponibles).to_string())

    return "\n".join(rapport)

# üìå G√©n√©ration du rapport
rapport_final = "üìä Suivi de l'√©volution des clusters avec moyennes pond√©r√©es (Correction D√©finitive Pandas)\n"
rapport_final += "======================================\n\n"
rapport_final += suivre_clusters_par_profil_pondere(df_merged)

# üìå Sauvegarde du rapport
with open(REPORT_FILE, "w", encoding="utf-8") as file:
    file.write(rapport_final)

print(f"‚úÖ Rapport g√©n√©r√© avec moyennes pond√©r√©es et correction compl√®te des warnings : {REPORT_FILE}")
