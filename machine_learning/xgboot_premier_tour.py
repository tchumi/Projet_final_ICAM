import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error

# ðŸ“‚ Chemin des donnÃ©es
data_path = "C:/Users/Admin.local/Documents/Projet_final_data/Piketty_data/elections_socio_fusionnes.csv"
df = pd.read_csv(data_path, dtype={"codecommune": str, "annÃ©e": int})

# ðŸ“Œ SÃ©lection des colonnes pertinentes pour le modÃ¨le du 1er tour
features_base = [
    'exprimes', 'voteG', 'voteCG', 'voteC', 'voteCD', 'voteD', 'voteTG', 'voteTD',
    'voteGCG', 'voteDCD', 'pvoteG', 'pvoteCG', 'pvoteC', 'pvoteCD', 'pvoteD',
    'pvoteTG', 'pvoteTD', 'pvoteTGratio', 'pvoteTDratio',
    'revratio', 'pchom', 'pouvr', 'pcadr', 'pibratio'
]
features_with_clusters = features_base + ["cluster_corrige_1er_tour"] if "cluster_corrige_1er_tour" in df.columns else features_base
target_columns = ['pvoteG', 'pvoteCG', 'pvoteC', 'pvoteCD', 'pvoteD', 'pvoteTG', 'pvoteTD']  # Variables cibles

# ðŸ“Œ Split Chronologique pour lâ€™EntraÃ®nement
train = df[df["annÃ©e"] <= 2012]
test = df[df["annÃ©e"] == 2017]
validation = df[df["annÃ©e"] == 2022]

# ðŸ“Œ Fonction pour entraÃ®ner et Ã©valuer un modÃ¨le XGBoost multivariÃ©
def train_evaluate_xgboost(train, test, features):
    X_train, y_train = train[features], train[target_columns]
    X_test, y_test = test[features], test[target_columns]

    # DÃ©finition et entraÃ®nement du modÃ¨le XGBoost
    model = xgb.XGBRegressor(objective="reg:squarederror", n_estimators=100, learning_rate=0.1, max_depth=6)
    model.fit(X_train, y_train)

    # PrÃ©dictions et Ã©valuation
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred, multioutput='uniform_average')
    
    return model, mae

# ðŸ“Œ ExpÃ©rimentation : Avec et Sans Clusters
print("ðŸ” EntraÃ®nement du modÃ¨le sans clusters...")
model_no_clusters, mae_no_clusters = train_evaluate_xgboost(train, test, features_base)

print("ðŸ” EntraÃ®nement du modÃ¨le avec clusters...")
model_with_clusters, mae_with_clusters = train_evaluate_xgboost(train, test, features_with_clusters)

# ðŸ“Š Comparaison des performances
print(f"ðŸ“‰ MAE Sans Clusters : {mae_no_clusters:.4f}")
print(f"ðŸ“‰ MAE Avec Clusters : {mae_with_clusters:.4f}")

# âœ… SÃ©lection du meilleur modÃ¨le et Ã©valuation finale sur 2022
best_model = model_with_clusters if mae_with_clusters < mae_no_clusters else model_no_clusters
X_validation, y_validation = validation[features_base], validation[target_columns]
y_pred_validation = best_model.predict(X_validation)
mae_validation = mean_absolute_error(y_validation, y_pred_validation, multioutput='uniform_average')

print(f"ðŸ“Š Validation Finale (2022) - MAE : {mae_validation:.4f}")
