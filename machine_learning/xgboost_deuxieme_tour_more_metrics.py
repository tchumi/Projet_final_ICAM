import pandas as pd
import xgboost as xgb
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from scipy.spatial.distance import cosine
from scipy.stats import entropy
import numpy as np

# ðŸ“‚ Chemin des donnÃ©es
data_path = "C:/Users/Admin.local/Documents/Projet_final_data/Piketty_data/elections_socio_fusionnes.csv"
output_report = "C:/Users/Admin.local/Documents/Projet_final_data/Piketty_data/prÃ©diction_XGBOOST_deuxieme_tour.txt"

df = pd.read_csv(data_path, dtype={"codecommune": str, "annÃ©e": int})

# ðŸ“Œ SÃ©lection des features pour le deuxiÃ¨me tour
features_2nd_tour = [
    'exprimesT2', 
    'revratio', 'pchom', 'pouvr', 'pcadr', 'pibratio',
    # Ajout des rÃ©sultats du 1er tour
    'pvoteG', 'pvoteCG', 'pvoteC', 'pvoteCD', 'pvoteD', 'pvoteTG', 'pvoteTD',
    'pvoteTGratio', 'pvoteTDratio'
]

# ðŸ“Œ SÃ©lection des cibles pour le deuxiÃ¨me tour
target_columns = ['pvoteT2_ED', 'pvoteT2_D', 'pvoteT2_CD', 'pvoteT2_C', 'pvoteT2_G']

# ðŸ“Œ Split Chronologique pour lâ€™EntraÃ®nement
train = df[df["annÃ©e"] <= 2012]
test = df[df["annÃ©e"] == 2017]
validation = df[df["annÃ©e"] == 2022]

# ðŸ“Œ Fonction pour entraÃ®ner et Ã©valuer XGBoost pour le deuxiÃ¨me tour
def train_evaluate_xgboost(train, test, validation, features):
    X_train, y_train = train[features], train[target_columns]
    X_test, y_test = test[features], test[target_columns]
    X_validation, y_validation = validation[features], validation[target_columns]

    # DÃ©finition et entraÃ®nement du modÃ¨le XGBoost
    model = xgb.XGBRegressor(objective="reg:squarederror", n_estimators=100, learning_rate=0.1, max_depth=6)
    model.fit(X_train, y_train)

    # PrÃ©dictions et Ã©valuation sur l'ensemble de test
    y_pred_test = model.predict(X_test)
    mae_test = mean_absolute_error(y_test, y_pred_test, multioutput='uniform_average')
    rmse_test = mean_squared_error(y_test, y_pred_test, squared=False)
    r2_test = r2_score(y_test, y_pred_test, multioutput='uniform_average')
    cosine_sim_test = 1 - cosine(y_test.values.flatten(), y_pred_test.flatten())
    kl_div_test = entropy(y_test.values.flatten(), y_pred_test.flatten())

    # PrÃ©dictions et Ã©valuation sur l'ensemble de validation
    y_pred_validation = model.predict(X_validation)
    mae_validation = mean_absolute_error(y_validation, y_pred_validation, multioutput='uniform_average')
    rmse_validation = mean_squared_error(y_validation, y_pred_validation, squared=False)
    r2_validation = r2_score(y_validation, y_pred_validation, multioutput='uniform_average')
    cosine_sim_validation = 1 - cosine(y_validation.values.flatten(), y_pred_validation.flatten())
    kl_div_validation = entropy(y_validation.values.flatten(), y_pred_validation.flatten())

    return model, {
        'mae_test': mae_test,
        'rmse_test': rmse_test,
        'r2_test': r2_test,
        'cosine_sim_test': cosine_sim_test,
        'kl_div_test': kl_div_test,
        'mae_validation': mae_validation,
        'rmse_validation': rmse_validation,
        'r2_validation': r2_validation,
        'cosine_sim_validation': cosine_sim_validation,
        'kl_div_validation': kl_div_validation
    }

# ðŸ“Œ EntraÃ®nement et Ã‰valuation
print("ðŸ” EntraÃ®nement du modÃ¨le pour le deuxiÃ¨me tour...")
model_2nd_tour, metrics = train_evaluate_xgboost(train, test, validation, features_2nd_tour)

# ðŸ“Š Affichage des rÃ©sultats
print(f"ï¿½ MAE pour le deuxiÃ¨me tour (Test 2017) : {metrics['mae_test']:.4f}")
print(f"ðŸ“‰ RMSE pour le deuxiÃ¨me tour (Test 2017) : {metrics['rmse_test']:.4f}")
print(f"ï¿½ RÂ² pour le deuxiÃ¨me tour (Test 2017) : {metrics['r2_test']:.4f}")
print(f"ï¿½ Cosine Similarity pour le deuxiÃ¨me tour (Test 2017) : {metrics['cosine_sim_test']:.4f}")
print(f"ï¿½ KL Divergence pour le deuxiÃ¨me tour (Test 2017) : {metrics['kl_div_test']:.4f}")

print(f"ðŸ“‰ MAE pour le deuxiÃ¨me tour (Validation 2022) : {metrics['mae_validation']:.4f}")
print(f"ðŸ“‰ RMSE pour le deuxiÃ¨me tour (Validation 2022) : {metrics['rmse_validation']:.4f}")
print(f"ðŸ“‰ RÂ² pour le deuxiÃ¨me tour (Validation 2022) : {metrics['r2_validation']:.4f}")
print(f"ðŸ“‰ Cosine Similarity pour le deuxiÃ¨me tour (Validation 2022) : {metrics['cosine_sim_validation']:.4f}")
print(f"ðŸ“‰ KL Divergence pour le deuxiÃ¨me tour (Validation 2022) : {metrics['kl_div_validation']:.4f}")

# ðŸ“Œ Enregistrement des rÃ©sultats dans un fichier
with open(output_report, 'w', encoding='utf-8') as f:
    f.write(f"ðŸ“‰ MAE pour le deuxiÃ¨me tour (Test 2017) : {metrics['mae_test']:.4f}\n")
    f.write(f"ðŸ“‰ RMSE pour le deuxiÃ¨me tour (Test 2017) : {metrics['rmse_test']:.4f}\n")
    f.write(f"ï¿½ RÂ² pour le deuxiÃ¨me tour (Test 2017) : {metrics['r2_test']:.4f}\n")
    f.write(f"ï¿½ Cosine Similarity pour le deuxiÃ¨me tour (Test 2017) : {metrics['cosine_sim_test']:.4f}\n")
    f.write(f"ï¿½ KL Divergence pour le deuxiÃ¨me tour (Test 2017) : {metrics['kl_div_test']:.4f}\n")
    f.write("\n")
    f.write(f"ðŸ“‰ MAE pour le deuxiÃ¨me tour (Validation 2022) : {metrics['mae_validation']:.4f}\n")
    f.write(f"ðŸ“‰ RMSE pour le deuxiÃ¨me tour (Validation 2022) : {metrics['rmse_validation']:.4f}\n")
    f.write(f"ï¿½ RÂ² pour le deuxiÃ¨me tour (Validation 2022) : {metrics['r2_validation']:.4f}\n")
    f.write(f"ðŸ“‰ Cosine Similarity pour le deuxiÃ¨me tour (Validation 2022) : {metrics['cosine_sim_validation']:.4f}\n")
    f.write(f"ðŸ“‰ KL Divergence pour le deuxiÃ¨me tour (Validation 2022) : {metrics['kl_div_validation']:.4f}\n")

print("\nâœ… Rapport gÃ©nÃ©rÃ© et enregistrÃ© dans 'prÃ©diction_XGBOOST_deuxieme_tour.txt'.")